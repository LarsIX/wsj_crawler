{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c10c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd \n",
    "from IPython.display import display, Markdown\n",
    "from merging_annotations import resolve_label_disagreements_AI, resolve_hype_disagreements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864d0fa",
   "metadata": {},
   "source": [
    "Review first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936f5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv files for the first batch\n",
    "first_batch_author = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\articles_WSJ_batch_one_author.csv\")\n",
    "first_batch_annotator = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\articles_WSJ_batch_one_annotator.csv\", encoding='cp1252') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b709c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution of hype level: hype_level\n",
      "0    64\n",
      "1    22\n",
      "2    12\n",
      "3     2\n",
      "Name: count, dtype: int64\n",
      "distribution of label_ai_related: label_ai_related\n",
      "0    59\n",
      "1    41\n",
      "Name: count, dtype: int64\n",
      "Number of articles with AI-related annotation: 41\n",
      "distribution of hype level author: hype_level\n",
      "1.0    15\n",
      "2.0     6\n",
      "0.0     5\n",
      "Name: count, dtype: int64\n",
      "distribution of label_ai_related author: label_ai_related\n",
      "0    74\n",
      "1    26\n",
      "Name: count, dtype: int64\n",
      "Number of articles with AI-related annotation author: 26\n"
     ]
    }
   ],
   "source": [
    "# investigate distribution of hype level and label_ai_related in annotator's annotation\n",
    "print(f\"distribution of hype level: {first_batch_annotator['hype_level'].value_counts()}\")\n",
    "print(f\"distribution of label_ai_related: {first_batch_annotator['label_ai_related'].value_counts()}\")\n",
    "print(f\"Number of articles with AI-related annotation: {first_batch_annotator['label_ai_related'].sum()}\")\n",
    "\n",
    "# investigate distribution of hype level and label_ai_related in aauthor's annotation\n",
    "print(f\"distribution of hype level author: {first_batch_author['hype_level'].value_counts()}\")\n",
    "print(f\"distribution of label_ai_related author: {first_batch_author['label_ai_related'].value_counts()}\")\n",
    "print(f\"Number of articles with AI-related annotation author: {first_batch_author['label_ai_related'].sum()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef4df58",
   "metadata": {},
   "source": [
    "Inspect the dataframes, ensure compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e485e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "52.0\n",
      "27.0\n",
      "[1. 2. 0. 3.]\n",
      "[0. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "# change the nan values to 0 in the author's dataframe\n",
    "first_batch_author['hype_level'] = first_batch_author['hype_level'].fillna(0) # change the nan values to 0 in the review dataframe\n",
    "\n",
    "# float hype_levels\n",
    "first_batch_annotator['hype_level'] = first_batch_annotator['hype_level'].astype(float) \n",
    "first_batch_author['hype_level'] = first_batch_author['hype_level'].astype(float) \n",
    "\n",
    "# check if datatype of the label column is float\n",
    "print(first_batch_annotator['hype_level'].dtype) \n",
    "print(first_batch_author['hype_level'].dtype)\n",
    "\n",
    "# check total values of hype levels in the review dataframe\n",
    "print(first_batch_annotator['hype_level'].sum()) # \n",
    "print(first_batch_author['hype_level'].sum()) #\n",
    "\n",
    "# print unique values of the hype level column in the review dataframe\n",
    "print(first_batch_annotator['hype_level'].unique()) \n",
    "print(first_batch_author['hype_level'].unique()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba879fd0",
   "metadata": {},
   "source": [
    "As a suggestion, the annotator labeled some articles as hype = 3, but the descision was made to set a max of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6de0d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "# set hype level to 2 if hype level is 3 in the review dataframe\n",
    "first_batch_annotator.loc[first_batch_annotator['hype_level'] == 3, 'hype_level'] = 2 \n",
    "\n",
    "# verify the change\n",
    "print(first_batch_annotator['hype_level'].unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b234d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of disagreement about AI-relatedness in the first batch: 0.19\n",
      "Fraction of disagreement at the hype level in the first batch: 0.32\n"
     ]
    }
   ],
   "source": [
    "# fraction of disagreement of label_ai_related in the first batch\n",
    "print(f\"Fraction of disagreement about AI-relatedness in the first batch: {len(first_batch_annotator[first_batch_annotator['label_ai_related'] != first_batch_author['label_ai_related']]) / len(first_batch_author)}\")\n",
    "\n",
    "# fraction of disagreement of hype level in the first batch\n",
    "print(f\"Fraction of disagreement at the hype level in the first batch: {len(first_batch_annotator[first_batch_annotator['hype_level'] != first_batch_author['hype_level']]) / len(first_batch_author)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the resolve_label_disagreements function to resolve the AI label disagreements between the two dataframes\n",
    "df_final_first_batch = resolve_label_disagreements(first_batch_author, first_batch_annotator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the resolve_hype_disagreements function to resolve the hype disagreements between the two dataframes\n",
    "df_final_first_batch = resolve_hype_disagreements(first_batch_author, df_final_first_batch)\n",
    "\n",
    "# write the final dataframe to a csv file\n",
    "df_final_first_batch.to_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\articles_WSJ_batch_one_final.csv\", index=False) # write the final dataframe to a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b801b",
   "metadata": {},
   "source": [
    "Review second batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62e0d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the second batches from csv files\n",
    "second_batch_annotator = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\articles_WSJ_batch_two_annotator.csv\")\n",
    "second_batch_author = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\articles_WSJ_batch_two_author.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb9c98",
   "metadata": {},
   "source": [
    "Inspect the dataframes, ensure compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e870373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the annotated second batch: Index(['article_id', 'title', 'sub_title', 'cleaned_corpus',\n",
      "       'label_ai_related', 'hype_level'],\n",
      "      dtype='object')\n",
      "Number of articles in the annotated second batch: 118\n"
     ]
    }
   ],
   "source": [
    "# print the columns of the annotated second batch\n",
    "print(f\"Columns in the annotated second batch: {second_batch_annotator.columns}\")\n",
    "\n",
    "# inspect the columns of the annotated second batch\n",
    "print(f\"Number of articles in the annotated second batch: {len(second_batch_annotator)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5086d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# align column names with authors annotation\n",
    "second_batch_annotator = second_batch_annotator.rename(columns={\"AI_RELEVANT\": \"label_ai_related\", \"HYPE_LEVEL\": \"hype_level\"})\n",
    "\n",
    "# change the nan values to 0 in the author's dataframe\n",
    "second_batch_author['hype_level'] = second_batch_author['hype_level'].fillna(0) # change the nan values to 0 in the review dataframe\n",
    "\n",
    "# float hype_levels\n",
    "second_batch_annotator['hype_level'] = second_batch_annotator['hype_level'].astype(float) \n",
    "second_batch_author['hype_level'] = second_batch_author['hype_level'].astype(float)\n",
    "\n",
    "# check if dtype of the label column is float\n",
    "print(second_batch_annotator['hype_level'].dtype)\n",
    "print(second_batch_author['hype_level'].dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d03c96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the hype level column in the annotated second batch: [0. 1. 2.]\n",
      "Values of the label_ai_related column in the annotated second batch: [0 1]\n",
      "Values of the hype level column in the author's second batch: [0. 1. 2.]\n",
      "Values of the label_ai_related column in the author's second batch: [0 1]\n",
      "Number of articles with AI-related annotation in the second batch: 21\n",
      "Number of articles with AI-related annotation in the second batch author: 7\n",
      "Total hype levels in the second batch: 24.0\n",
      "Total hype levels in the second batch author: 8.0\n"
     ]
    }
   ],
   "source": [
    "# print the values of the hype level column in the annotators second batch\n",
    "print(f\"Values of the hype level column in the annotated second batch: {second_batch_annotator['hype_level'].unique()}\")\n",
    "\n",
    "# print the values of the label_ai_related column in the annotators second batch\n",
    "print(f\"Values of the label_ai_related column in the annotated second batch: {second_batch_annotator['label_ai_related'].unique()}\")\n",
    "\n",
    "# print the values of the hype level column in the author's second batch\n",
    "print(f\"Values of the hype level column in the author's second batch: {second_batch_author['hype_level'].unique()}\")\n",
    "\n",
    "# print the values of the label_ai_related column in the author's second batch\n",
    "print(f\"Values of the label_ai_related column in the author's second batch: {second_batch_author['label_ai_related'].unique()}\")\n",
    "\n",
    "# number of articles with AI-related annotation in the second batch\n",
    "print(f\"Number of articles with AI-related annotation in the second batch: {second_batch_annotator['label_ai_related'].sum()}\")\n",
    "\n",
    "# number of articles with AI-related annotation in the second batch author\n",
    "print(f\"Number of articles with AI-related annotation in the second batch author: {second_batch_author['label_ai_related'].sum()}\")\n",
    "\n",
    "# total hype levels in the second batch\n",
    "print(f\"Total hype levels in the second batch: {second_batch_annotator['hype_level'].sum()}\")\n",
    "\n",
    "# total hype levels in the second batch author\n",
    "print(f\"Total hype levels in the second batch author: {second_batch_author['hype_level'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d67c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of disagreement about AI-relatedness in the first batch: 0.11864406779661017\n",
      "Fraction of disagreement at the hype level in the first batch: 0.11864406779661017\n"
     ]
    }
   ],
   "source": [
    "# fraction of disagreement of label_ai_related in the first batch\n",
    "print(f\"Fraction of disagreement about AI-relatedness in the first batch: {len(second_batch_annotator[second_batch_annotator['label_ai_related'] != second_batch_author['label_ai_related']]) / len(second_batch_author)}\")\n",
    "\n",
    "# fraction of disagreement of hype level in the first batch\n",
    "print(f\"Fraction of disagreement at the hype level in the first batch: {len(second_batch_annotator[second_batch_annotator['hype_level'] != second_batch_author['hype_level']]) / len(second_batch_author)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the label disagreements between the two dataframes using the resolve_label_disagreements function\n",
    "df_ai_level_merge  = resolve_label_disagreements_AI(second_batch_author, second_batch_annotator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check df_ai_level_merge\n",
    "print(f\"Number of changes in the merged dataframe: {df_ai_level_merge['modified'].sum()}\")\n",
    "print(f\"Number of articles with ai-related annotation: {df_ai_level_merge['label_ai_related'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2615e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the nan values to 0 in the author's dataframe\n",
    "second_batch_author['hype_level'] = second_batch_author['hype_level'].fillna(0) # change the nan values to 0 in the review dataframe\n",
    "\n",
    "# float hype_levels\n",
    "df_ai_level_merge['hype_level'] = df_ai_level_merge['hype_level'].astype(float) # convert the hype level column to int\n",
    "second_batch_author['hype_level'] = second_batch_author['hype_level'].astype(float) # convert the hype level column to int\n",
    "\n",
    "# check if type of the label column is float\n",
    "print(df_ai_level_merge['hype_level'].dtype) # check the type of the label column\t\n",
    "print(second_batch_author['hype_level'].dtype) # check the type of the label column\n",
    "\n",
    "# check total values of hype levels in the review dataframe\n",
    "print(df_ai_level_merge['hype_level'].sum()) # \n",
    "print(second_batch_author['hype_level'].sum()) #\n",
    "\n",
    "# print unique values of the hype level column in the review dataframe\n",
    "print(df_ai_level_merge['hype_level'].unique()) # check the unique values of the hype level column in the review dataframe\n",
    "print(second_batch_author['hype_level'].unique()) # check the unique values of the hype level column in the author dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbbaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the resolve_hype_disagreements function to resolve the hype disagreements between the two dataframes\n",
    "df_final_second_batch = resolve_hype_disagreements(second_batch_author, df_ai_level_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the final dataframe to a csv file\n",
    "df_final_second_batch.to_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\second_batch_WSJ_final.csv\", index=False) # write the final dataframe to a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1620191",
   "metadata": {},
   "source": [
    "Review third batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3928d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the third batches from csv files\n",
    "third_batch_annotator = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\articles_WSJ_batch_three_annotator.csv\")\n",
    "third_batch_author = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\articles_WSJ_batch_three_author.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a6c1b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the annotated third batch: Index(['article_id', 'index_id', 'scanned_time', 'title', 'sub_title',\n",
      "       'corpus', 'AI_Relevant', 'Hype_Level', 'section', 'date'],\n",
      "      dtype='object')\n",
      "Number of articles in the annotated third batch: 100\n"
     ]
    }
   ],
   "source": [
    "# print the columns of the annotated third batch\n",
    "print(f\"Columns in the annotated third batch: {third_batch_annotator.columns}\")\n",
    "\n",
    "# inspect the columns of the annotated third batch\n",
    "print(f\"Number of articles in the annotated third batch: {len(third_batch_annotator)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0884caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "The total hype levels in the annotator's dataframe: 46.0\n",
      "The total hype levels in the author's dataframe: 41.0\n",
      "The total ai_reated levels in the annotator's dataframe: 35\n",
      "The total ai_reated levels in the author's dataframe: 29\n",
      "The total differences in hype classification: 15\n",
      "The total differences in hype classification: 8\n"
     ]
    }
   ],
   "source": [
    "# align column names with authors annotation\n",
    "third_batch_annotator = third_batch_annotator.rename(columns={\"AI_Relevant\": \"label_ai_related\", \"Hype_Level\": \"hype_level\"})\n",
    "\n",
    "# change the nan values to 0 in the author's dataframe\n",
    "third_batch_author['hype_level'] = third_batch_author['hype_level'].fillna(0) # change the nan values to 0 in the review dataframe\n",
    "\n",
    "# float hype_levels\n",
    "third_batch_annotator['hype_level'] = third_batch_annotator['hype_level'].astype(float) # convert the hype level column to int\n",
    "third_batch_author['hype_level'] = third_batch_author['hype_level'].astype(float) # convert the hype level column to int\n",
    "\n",
    "# check if type of the label column is float\n",
    "print(third_batch_annotator['hype_level'].dtype) # check the type of the label column\t\n",
    "print(third_batch_author['hype_level'].dtype) # check the type of the label column\n",
    "\n",
    "# compare the hype levels in the two dataframes\n",
    "print(f'The total hype levels in the annotator\\'s dataframe: {third_batch_annotator[\"hype_level\"].sum()}')\n",
    "print(f'The total hype levels in the author\\'s dataframe: {third_batch_author[\"hype_level\"].sum()}')\n",
    "\n",
    "# compare the ai_reated levels in the two dataframes\n",
    "print(f'The total ai_reated levels in the annotator\\'s dataframe: {third_batch_annotator[\"label_ai_related\"].sum()}')\n",
    "print(f'The total ai_reated levels in the author\\'s dataframe: {third_batch_author[\"label_ai_related\"].sum()}')\n",
    "\n",
    "# compare total differences in classification\n",
    "print(f'The total differences in hype classification: {len(third_batch_annotator[third_batch_annotator[\"hype_level\"] != third_batch_author[\"hype_level\"]])}')\n",
    "print(f'The total differences in hype classification: {len(third_batch_annotator[third_batch_annotator[\"label_ai_related\"] != third_batch_author[\"label_ai_related\"]])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9868f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of disagreement about AI-relatedness in the first batch: 0.08\n",
      "Fraction of disagreement at the hype level in the first batch: 0.15\n"
     ]
    }
   ],
   "source": [
    "# fraction of disagreement of label_ai_related in the first batch\n",
    "print(f\"Fraction of disagreement about AI-relatedness in the first batch: {len(third_batch_annotator[third_batch_annotator['label_ai_related'] != third_batch_author['label_ai_related']]) / len(third_batch_author)}\")\n",
    "\n",
    "# fraction of disagreement of hype level in the first batch\n",
    "print(f\"Fraction of disagreement at the hype level in the first batch: {len(third_batch_annotator[third_batch_annotator['hype_level'] != third_batch_author['hype_level']]) / len(third_batch_author)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82052e7d",
   "metadata": {},
   "source": [
    "Resolve disagreements between the author and the annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da527651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the label disagreements between the two dataframes using the resolve_label_disagreements function\n",
    "third_df_ai_level_merge = resolve_label_disagreements_AI(third_batch_author, third_batch_annotator)\n",
    "\n",
    "# use the resolve_hype_disagreements function to resolve the hype disagreements between the two dataframes\n",
    "df_final_third_batch = resolve_hype_disagreements(third_batch_author, third_df_ai_level_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58bf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles in the third sample: 100\n",
      "columns in the third sample: Index(['article_id', 'index_id', 'scanned_time', 'title', 'sub_title',\n",
      "       'corpus', 'label_ai_related', 'hype_level', 'section', 'date',\n",
      "       'modified', 'hype_level_change'],\n",
      "      dtype='object')\n",
      "Number of articles with ai-related annotation: 35\n"
     ]
    }
   ],
   "source": [
    "# verify the annotation process\n",
    "print(f\"Number of articles in the third sample: {len(df_final_third_batch)}\")\n",
    "print(f\"columns in the third sample: {df_final_third_batch.columns}\")\n",
    "print(f\"Number of articles with ai-related annotation: {df_final_third_batch['label_ai_related'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dfde923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the final dataframe to a csv file\n",
    "df_final_third_batch.to_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\third_batch_WSJ_final.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d99e8a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles in the third sample: 100\n",
      "columns in the third sample: Index(['article_id', 'index_id', 'scanned_time', 'title', 'sub_title',\n",
      "       'corpus', 'label_ai_related', 'hype_level', 'section', 'date',\n",
      "       'modified', 'hype_level_change'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# verify the csv\n",
    "df_final_third_batch = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Masterarbeit\\Code\\WSJ\\Annotation\\third_batch_WSJ_final.csv\")\n",
    "print(f\"Number of articles in the third sample: {len(df_final_third_batch)}\")\n",
    "print(f\"columns in the third sample: {df_final_third_batch.columns}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
